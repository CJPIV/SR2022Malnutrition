---
title: "Feature_Selection"
author: "Jim Perry"
date: "5/25/2022"
output: pdf_document
---
This R script includes feature selection methods that were used to determine 
important features for RandomForest and SVM classification and association rule
learning. The returned features from this list were later used in the 
classification and ARL R scripts.
All scripts run Stunting data first, then Thinness.

```{r DATA PREPARATION}
stunting = read.csv("C:/Users/Carmen Perry/Desktop/Colgate Stuff/Summer Research 2022/MalnutritionProject-20220523T125732Z-001/MalnutritionProject/Code/SR2022Malnutrition/Data/forFS_Stunting.csv")
thinness = read.csv("C:/Users/Carmen Perry/Desktop/Colgate Stuff/Summer Research 2022/MalnutritionProject-20220523T125732Z-001/MalnutritionProject/Code/SR2022Malnutrition/Data/forFS_Thinness.csv")

NUM_FOLDS = 10 #Change accordingly
trainList = list(train1, train2, train3, train4, train5,
                 train6, train7, train8, train9, train10)
training = rbind(train1, train2, train3, train4, train5,
                 train6, train7, train8, train9, train10)

testList = list(test1, test2, test3, test4, test5,
                 test6, test7, test8, test9, test10)
testing = rbind(test1, test2, test3, test4, test5,
                 test6, test7, test8, test9, test10)
set.seed(13)

```

```{r ReliefF}
library(FSelectorRcpp)
relF = relief(Stunting~., stunting, neighboursCount = 5)
FS_relF_Stunting = relF[order(relF$importance), ] #returns a list of important features and their ranking

relF = relief(Thinness~., thinness, neighboursCount = 5)
FS_relF_Thinness = relF[order(relF$importance), ]
```

```{r InfoGain}
#install.packages("FSelectorRcpp")
library(FSelectorRcpp)

infogain = information_gain(Stunting~., data = stunting, type = 'infogain')
FS_InfoG_Stunting = infogain[order(infogain$importance), ] #returns a list of important features and their ranking

infogain = information_gain(Thinness~., data = thinness, type = 'infogain')
FS_InfoG_Thinness = infogain[order(infogain$importance), ]
```

```{r mRMR}
#install.packages("mRMRe")
library(mRMRe)

mrmr = mRMR.data(data = stunting)
FS_MRMR_Stunting = mRMR.classic(data = mrmr)

mrmr = mRMR.data(data = thinness)
FS_MRMR_Thinness = mRMR.classic(data = mrmr)
```

```{r JMI}

```
'
```{r Univariate Logistic Regression}
library(dplyr)       # For data manipulation (dplyr) 
library(broom)       # For making model summary tidy
library(visreg)      # For plotting logodds and probability 
library(rcompanion)  # To calculate pseudo R-squared
library(MASS)        # For stepwise model selection
library(ROCR)        # To find the probability threshold for best accuracy
library(car)         # For multicollinearity function vif()

LoR_Stunting = read.csv('C:/Users/Carmen Perry/Desktop/Colgate Stuff/Summer Research 2022/MalnutritionProject-20220523T125732Z-001/MalnutritionProject/Code/SR2022Malnutrition/Data/stunting.csv')

#Train/test splits
set.seed(13)  
train_indices = sample(1:n, 0.9*nrow(LM_data))  # Create a vector of indices which is an 90% random sample
train = LM_data[train_indices, ]     # Subset the Diabetes data frame to training indices only
test = LM_data[-train_indices, ]     # Exclude the training indices to create the test data set
paste("train sample size: ", dim(train)[1])   # Training sample size
paste("test sample size: ", dim(test)[1])     # Test sample size
```


```{r Literature-based selection}

```