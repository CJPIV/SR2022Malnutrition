---
title: "Preprocessing"
author: "Jim Perry"
date: "5/25/2022"
output: pdf_document
---
1036 total samples collected.
97 independent variables, 1 dependent variable (per dataset; both stunting and
thinness have their own datasets).

Code is divided into blocks; each block performs tasks relating to a specific
task, as labelled by the title at the top of the block. The block below, for 
example, is called "Import Data & Clean Data".

IMPORTING, CLEANING DATA:
  - Importing data from .csv files into R, converting factors for machine 
    readability.
```{r Importing & Cleaning Data}
stunting = read.csv("C:/Users/Carmen Perry/Desktop/Colgate Stuff/Summer Research 2022/MalnutritionProject-20220523T125732Z-001/MalnutritionProject/Code/SR2022Malnutrition/Data/stunting.csv")
thinness = read.csv("C:/Users/Carmen Perry/Desktop/Colgate Stuff/Summer Research 2022/MalnutritionProject-20220523T125732Z-001/MalnutritionProject/Code/SR2022Malnutrition/Data/thinness.csv")

names = c(2,6:8,10,12,14:43,46:61,63:78) # saves the column number of the categorical risk factors
stunting[,names] = lapply(stunting[,names], factor) # converts these columns to factor data
thinness[,names] = lapply(thinness[,names], factor) # converts these columns to factor data
```
K-NEAREST NEIGHBOR IMPUTATION:
  - "Fills in" missing specific datapoints using the k-NN algorithm (here k=5).
  - Run twice: once for categorical variables, once for numerical variables.

```{r k-NN to complete dataset}
library(VIM)
#Imputing categorical variables with k=5 neighbors.

priorStunting = stunting
stunting = kNN(stunting, variable = names, k=5)
stunting = subset(stunting, select = Age:Stunting)

thinness = kNN(thinness, variable = names, k=5)
thinness = subset(thinness, select = Age:Thinness)

##########################################################
#Imputing numerical variables with k=5 neighbors.

numbnames = c(1,9,11,13,44,45,62)
stunting[, numbnames] = as.data.frame(lapply(stunting[, numbnames], as.numeric))
thinness[, numbnames] = as.data.frame(lapply(thinness[, numbnames], as.numeric))

stunting = kNN(stunting, variable = numbnames, k=5)
stunting = subset(stunting, select = Age:Stunting)

thinness = kNN(thinness, variable = numbnames, k=5)
thinness = subset(thinness, select = Age:Thinness)
```

ONE-HOT ENCODING, FILE OUTPUT:
  - Applies one-hot encoding to categorical data columns. Returns all n factors,
    which are then manually edited to return as (n-1) columns per category.
  - As OHE is the last step, this also outputs our now-preprocessed data.
```{r One-hot encoding, file preparation}
# install.packages('fastDummies')
library(fastDummies)
#One-hot encode Stunting data, output processed file
stunting = dummy_cols(.data = stunting, ignore_na = TRUE)
stunting = subset(stunting, select = -c(2,6:8,10,12,14:43,46:61,63:78))
stunting = subset(stunting, select = 
                    -c(13,14,17,19,21,23,25,27,28,33,34,35,37,39,41,48,51,52,54,
                       55,57,59,60,61,63,65,67,69,71,73,75,77,79,80,82,84,86,90,
                       88,91,93,97,98,95,103,104,107,113,116,119,122,125,128,
                       129,134,137,140,144,148,151,154,157,160,161,163,165,167,
                       171,173,175,177,179,181,183,185,187))
write.csv(stunting, file = 'PROCStunting.csv')

thinness = dummy_cols(.data = thinness, ignore_na = TRUE)
thinness = subset(thinness, select = -c(2,6:8, 10, 12, 14:43, 46:61, 63:78))
thinness = subset(thinness, select = 
                    -c(13,14,17,19,21,23,25,27,28,33,34,35,37,39,41,48,51,52,54,
                       55,57,59,60,61,63,65,67,69,71,73,75,77,79,80,82,84,86,90,
                       88,91,93,97,98,95,103,104,107,113,116,119,122,125,128,
                       129,134,137,140,144,148,151,154,157,160,161,163,165,167,
                       171,173,175,177,179,181,183,185,187))
write.csv(thinness, file = 'PROCThinness.csv')
```