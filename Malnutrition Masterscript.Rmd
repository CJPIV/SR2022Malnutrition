---
title: "Malnutrition Masterscript"
author: "Jim Perry"
date: "5/30/2022"
output: pdf_document
---
# PREPROCESSING: Preparing data from original survey for use in statistical/ML analysis.
#####
```{r Import Data}
#Reading and cleaning the original spreadsheet from the survey.
library(readxl)
library(dplyr)

SURVEY = read_excel("SURVEY.xlsx")
SURVEY = SURVEY[-1,] #First row is a misread full of NAs - drop it
SURVEY = SURVEY[,-c(35, 54, 115, 134)] #Empty columns

#Now the fun part - manually rename any weird variable names
names(SURVEY)[13] = "Class" #Which class in the grade is the child in?
names(SURVEY)[17] = "FamilySize"
names(SURVEY)[18] = "NumOldBros"
names(SURVEY)[19] = "Bros<12?"
names(SURVEY)[20] = "Vaccine"
names(SURVEY)[21] = "BCGScar"
names(SURVEY)[22] = "FeverLast2Weeks"
names(SURVEY)[23] = "FeverQuantity"
names(SURVEY)[24] = "DiarrheaLast2Weeks"
names(SURVEY)[25] = "DiarrheaQuantity"
names(SURVEY)[26] = "CoughLast2Weeks"
names(SURVEY)[27] = "CoughQuantity"
names(SURVEY)[28] = "NailsTrimmed"
names(SURVEY)[29] = "NailsDirty"
names(SURVEY)[30] = "NailTrimFrequency"
names(SURVEY)[31] = "SchoolLat"
names(SURVEY)[32] = "SchoolLatDoors"
names(SURVEY)[33] = "SchoolLatFlies"
names(SURVEY)[34] = "SchoolLatVisibleStool"
names(SURVEY)[35] = "HeardOfAL"
names(SURVEY)[36] = "HeardOfTT"
names(SURVEY)[37] = "HeardOfHW"
names(SURVEY)[38] = "HeardOfHIV"
names(SURVEY)[39] = "HeardOfWorms"
names(SURVEY)[40] = "HeardOfMalaria"
names(SURVEY)[41] = "HeardOfTB"
names(SURVEY)[42] = "HeardOfSCh"
names(SURVEY)[43] = "ToldByFam"
names(SURVEY)[44] = "ToldByHP"
names(SURVEY)[45] = "ToldByTeacher"
names(SURVEY)[46] = "ToldByMedia"
names(SURVEY)[47] = "KnowWormsSpread"
names(SURVEY)[48] = "HowKnowWormsSpread"
names(SURVEY)[49] = "KnowWormsBad"
names(SURVEY)[50] = "HowKnowWormsBad"
names(SURVEY)[51] = "KnowAvoidWorms"
names(SURVEY)[52] = "HowKnowAvoidWorms"
names(SURVEY)[53] = "WhereLive"
names(SURVEY)[54] = "Address"
names(SURVEY)[55] = "Occupation"
names(SURVEY)[56] = "MomEduc"
names(SURVEY)[57] = "HouseFloorMats"
names(SURVEY)[58] = "KitchenSeparate"
names(SURVEY)[59] = "SepKitchenMats"
names(SURVEY)[60] = "SepKitchenRoof"
names(SURVEY)[61] = "SepKitchenWall"
names(SURVEY)[62] = "SepKitchenNeither" #Should be able to get removed in 1HE
names(SURVEY)[63] = "CookWood"
names(SURVEY)[64] = "CookGas"
names(SURVEY)[65] = "CookCoal"
names(SURVEY)[66] = "CookKerosine"
names(SURVEY)[67] = "CookElectric"
names(SURVEY)[68] = "Electricity"
names(SURVEY)[69] = "Radio"
names(SURVEY)[70] = "TV"
names(SURVEY)[71] = "Phone"
names(SURVEY)[72] = "WhyPhone"
names(SURVEY)[73] = "Cattle"
names(SURVEY)[74] = "SheepGoat"
names(SURVEY)[75] = "Chicken"
names(SURVEY)[76] = "HousePet"
names(SURVEY)[77] = "NoAnimal"
names(SURVEY)[78] = "HouseHasWater"
names(SURVEY)[79] = "WhereGetWater"
names(SURVEY)[80] = "WaterTreated"
names(SURVEY)[81] = "HowTreat"
names(SURVEY)[82] = "FamLat"
names(SURVEY)[83] = "LatInside"
names(SURVEY)[84] = "LatDistanceHouse"
names(SURVEY)[85] = "LatDistanceKitchen"
names(SURVEY)[86] = "LatConnectedTo"
names(SURVEY)[87] = "RiverBathFrequency"
names(SURVEY)[88] = "RiverLaundryFrequency"
names(SURVEY)[89] = "DefecateField"
names(SURVEY)[90] = "UseSchoolLat"
names(SURVEY)[91] = "UseTP"
names(SURVEY)[92] = "WashHandsLat"
names(SURVEY)[93] = "WashHandsLatHow"
names(SURVEY)[94] = "WashHandsSoapLatFrequency"
names(SURVEY)[95] = "WashHandsEat"
names(SURVEY)[96] = "WashHandsEatHow"
names(SURVEY)[97] = "WashHandsSoapEatFrequency"
names(SURVEY)[98] = "EatSoil"
names(SURVEY)[99] = "FavFruit"
names(SURVEY)[100] = "WashFruit"
names(SURVEY)[101] = "EatRawVeg"
names(SURVEY)[102] = "WashRawVegFrequency"
names(SURVEY)[103] = "WalkBarefoot"
names(SURVEY)[104] = "HomeShoeOrSandal"
names(SURVEY)[105] = "ForWhatBarefoot"
names(SURVEY)[106] = "DewormPill"
names(SURVEY)[107] = "WhenDewormPill"
names(SURVEY)[108] = "Antibiotics"
names(SURVEY)[109] = "MostFreqFood"
names(SURVEY)[110] = "TakesMeds"
names(SURVEY)[111] = "Name/TypeOfMeds"
names(SURVEY)[112] = "AntiMalaria3Months"
names(SURVEY)[113] = "Wheezing"
names(SURVEY)[114] = "Wheezing2Yrs"
names(SURVEY)[115] = "Wheezing1Yr"
names(SURVEY)[116] = "Wheezing1YrQuantity"
names(SURVEY)[117] = "Asthma"
names(SURVEY)[118] = "Asthma2Yrs"
names(SURVEY)[119] = "Asthma1Yr"
names(SURVEY)[120] = "DocConfirmedAsthma"
names(SURVEY)[121] = "Rash"
names(SURVEY)[122] = "RashElbow"
names(SURVEY)[123] = "RashKnees"
names(SURVEY)[124] = "RashAnkles"
names(SURVEY)[125] = "RashButt"
names(SURVEY)[126] = "RashNeck"
names(SURVEY)[127] = "RashEyesEars"
names(SURVEY)[128] = "HayFever"
names(SURVEY)[129] = "HayFever2Yrs"
names(SURVEY)[130] = "HayFever1Yr"

SURVEY = SURVEY[,-c(1, 7, 8, 9)] #Don't need these columns; I forgot to remove them earlier, and doing so now would mean I'd have to re-index the >100 variable renames I just did above. No way.
```



```{r Handling NAs & Datatype Conversions, warning = FALSE}
reducedSurvey = SURVEY[,-c(44, 46, 48, 51, 64, 95, 101, 105, 107)] #Potential candidates for removal from dataset; we'll work with this, as I think these changes will end up in the final iteration.
################################################################################
#1HE "Where do you get your water from?"
tapWater = c()
WaterFromNeighbor = c()
WaterFromRiver = c()
WaterFromWell = c()
WaterFromTank = c()

for (i in 1:1036){
  if (is.na(reducedSurvey[[i, 70]])){
    tapWater[[i]] = 0
    WaterFromNeighbor[[i]] = 0
    WaterFromRiver[[i]] = 0
    WaterFromWell[[i]] = 0
    WaterFromTank[[i]] = 0
    next
  }
  if (tolower(reducedSurvey[[i, 70]]) == "tap water"){
    tapWater[[i]] = 1
    WaterFromNeighbor[[i]] = 0
    WaterFromRiver[[i]] = 0
    WaterFromWell[[i]] = 0
    WaterFromTank[[i]] = 0
  }else if (reducedSurvey[[i, 70]] == 0){
    tapWater[[i]] = 0
    WaterFromNeighbor[[i]] = 1
    WaterFromRiver[[i]] = 0
    WaterFromWell[[i]] = 0
    WaterFromTank[[i]] = 0
  }else if (reducedSurvey[[i, 70]] == 1){
    tapWater[[i]] = 0
    WaterFromNeighbor[[i]] = 0
    WaterFromRiver[[i]] = 1
    WaterFromWell[[i]] = 0
    WaterFromTank[[i]] = 0
  }else if (reducedSurvey[[i, 70]] == 2){
    tapWater[[i]] = 0
    WaterFromNeighbor[[i]] = 0
    WaterFromRiver[[i]] = 0
    WaterFromWell[[i]] = 1
    WaterFromTank[[i]] = 0
  }else if (reducedSurvey[[i, 70]] == 4){
    tapWater[[i]] = 0
    WaterFromNeighbor[[i]] = 0
    WaterFromRiver[[i]] = 0
    WaterFromWell[[i]] = 0
    WaterFromTank[[i]] = 1
  }
}
tapWater = as.numeric(as.character(tapWater))
reducedSurvey[[70]] = tapWater
names(reducedSurvey)[[70]] = "WaterFromTap"

WaterFromNeighbor = as.numeric(as.character(WaterFromNeighbor))
reducedSurvey[[117]] = WaterFromNeighbor
names(reducedSurvey)[[117]] = "WaterFromNeighbor"

WaterFromRiver = as.numeric(as.character(WaterFromRiver))
reducedSurvey[[118]] = WaterFromRiver
names(reducedSurvey)[[118]] = "WaterFromRiver"

WaterFromWell = as.numeric(as.character(WaterFromWell))
reducedSurvey[[119]] = WaterFromWell
names(reducedSurvey)[[119]] = "WaterFromWell"

WaterFromTank = as.numeric(as.character(WaterFromTank))
reducedSurvey[[120]] = WaterFromTank
names(reducedSurvey)[[120]] = "WaterFromTank"

################################################################################
#1HE Rural/Suburban/Urban split
rural = c()
urban = c()
for (i in 1:1036){
  if (is.na(reducedSurvey[[i, 46]])){
      next
  }
  neighborhood = reducedSurvey[[i, 46]]
  if(neighborhood == 0){
      urban[[i]] = 1
      rural[[i]] = 0
  }else if(neighborhood == 1){
    rural[[i]] = 1
    urban[[i]] = 0
    }
}
urban = as.numeric(as.character(urban))
reducedSurvey[[46]] = urban
names(reducedSurvey)[[46]] = "Urban"
rural = as.numeric(as.character(rural)) #Can't convert directly from double to numeric
reducedSurvey[[47]] = rural# = replace(reducedSurvey, reducedSurvey$Address, rural)
names(reducedSurvey)[[47]] = "Rural"
################################################################################
#Remove units from measurements so they can be converted to numerics
for (i in 1:1036){
  distance = reducedSurvey[[i, 75]]
  reducedSurvey[[i, 75]] = substr(distance, 1, length(distance))
  distance2 = reducedSurvey[[i, 76]]
  reducedSurvey[[i, 76]] = substr(distance2, 1, length(distance2))
  whenDeworm = reducedSurvey[[i, 96]]
  reducedSurvey[[i, 96]] = substr(whenDeworm, 1, length(whenDeworm))

}
reducedSurvey[[75]] = as.numeric(reducedSurvey[[75]]) #Can typecast directly to numeric
reducedSurvey[[76]] = as.numeric(reducedSurvey[[76]])
reducedSurvey[[96]] = as.numeric(reducedSurvey[[96]])
################################################################################
#These factors have number measurements but are of datatype "character"; simple conversion to datatype "numeric"
changeInds = c(19, 21, 23, 31:42, 50:59, 64:68, 72, 76, 77, 82:117)
for (factor in changeInds){
  reducedSurvey[[factor]] = as.numeric(reducedSurvey[[factor]])
}
################################################################################
#Drop "Class"? Doesn't seem specific enough to be useful.
reducedSurvey = reducedSurvey[, -9]
################################################################################
#Adjusting data values
#Convert "99"s in numeric factors to "Na"s for later imputation under kNN algorithm
for (sample in 1:1036){
  for (factor in 11:116) #Columns where 99s indicate "I don't know" as a possible answer
    if (is.na(reducedSurvey[[sample, factor]])){
      next
    }else if (reducedSurvey[[sample, factor]] == 99){
      reducedSurvey[[sample, factor]] = NA
    }
}

#A sample's height was misinput as 92.00 meters.
for (sample in 1:1036){
  if (reducedSurvey[[sample, 10]] == 92.00){ 
    reducedSurvey[[sample, 10]] = NA
    break
  }
}

#Impute conditional responses where "NA" implies 0
for (sample in 1:1036){
  for (factor in c(18, 20, 22, 31:41, 53, 55:58, 64:67, 71, 95, 109:113)){
    if (is.na(reducedSurvey[[sample, factor]])){
      reducedSurvey[[sample, factor]] = 0
    }
  }
}

#These columns were input as a different binary; as "NA/0" instead of "0/1"
for (sample in 1:1036){
  for (factor in c(30, 54, 63)){ 
    if (is.na(reducedSurvey[[sample, factor]])){
      reducedSurvey[[sample, factor]] = 0
    }else if (reducedSurvey[[sample, factor]] == 0){
      reducedSurvey[[sample, factor]] = 1
    }else{
      reducedSurvey[[sample, factor]] = 0
    }
  }
}

#Convert different numeric binaries 0/2 binaries into 0/1
for (sample in 1:1036){
  for (factor in c(49, 65)){
    if (is.na(reducedSurvey[[sample, factor]])){
      next
    }else if (reducedSurvey[[sample, factor]] == 2){
      reducedSurvey[[sample, factor]] = 1
    }else if (reducedSurvey[[sample, factor]] != 0){
      reducedSurvey[[sample, factor]] = NA
    }
  }
}
#CookElectric's binary is 0/4; converting into 0/1
for (sample in 1:1036){{
    if (is.na(reducedSurvey[[sample, 58]])){
      next
    }else if (reducedSurvey[[sample, 58]] == 4){
      reducedSurvey[[sample, 58]] = 1
    }else if (reducedSurvey[[sample, 58]] != 0){
      reducedSurvey[[sample, 58]] = NA
    }
  }
}
#0/3 here
for (sample in 1:1036){{
    if (is.na(reducedSurvey[[sample, 66]])){
      reducedSurvey[[sample, 66]] = 0
    }else if (reducedSurvey[[sample, 66]] == 3){
      reducedSurvey[[sample, 66]] = 1
    }else if (reducedSurvey[[sample, 6]] != 0){
      reducedSurvey[[sample, 66]] = NA
    }
  }
}
#I don't know why this code in the above loop doesn't work. I don't know why it does work when placed into its own loop. Code is mysterious; let's hope this desire for loop autonomy doesn't spread
for (sample in 1:1036){{
    if (is.na(reducedSurvey[[sample, 66]])){
      reducedSurvey[[sample, 66]] = 0
    }
  }
}

#copySet = reducedSurvey
#reducedSurvey = copySet

#Setting weird values in binary vectors (anything that's not 0/1) to NA for imputation
for (sample in 1:1036){
  for (factor in c(15, 16, 21, 23, 24, 49, 51, 58, 65, 68, 72:73)){
    if (is.na(reducedSurvey[[sample, factor]])){
      next
    }else if ((reducedSurvey[[sample, factor]] != 0) & (reducedSurvey[[sample, factor]] != 1)){
      reducedSurvey[[sample, factor]] = NA
    }
  }
}



reducedSurvey$HouseFloorMats = tolower(reducedSurvey$HouseFloorMats)

#Getting rid of some more weird values
for (sample in 1:1036){
  for (factor in c(85:86))
  if (is.na(reducedSurvey[[sample, factor]])){
    next
  }
  else if (reducedSurvey[[sample, factor]] == 21 || reducedSurvey[[sample, factor]] == 10){
    reducedSurvey[[sample, factor]] = NA
  }
}

for (sample in 1:1036){
  if (is.na(reducedSurvey[[sample, 10]])){
    next
  }
  else if (reducedSurvey[[sample, 10]] == 1.79){
    reducedSurvey[[sample, 10]] = 1.29
  }
}

```



```{r One Hot Encoding}
library(VIM)
library(fastDummies)

#1HE nominal categoricals
#I already encoded some of these by hand in the last code block, but the remainder can be handled by this imported function
oneHotEncoded = dummy_cols(.data = reducedSurvey,
                     ignore_na = TRUE,
                     remove_first_dummy =  TRUE,
                     split = ",")
oneHotEncoded = oneHotEncoded[,-c(48, 123)] #One category got broken up and the other was created to account for a sample answer that got misinput as both
```



```{r Final Layer of Data Handling, warning = FALSE}
#Handle variables we decided to remove or calculate differently after I wrote 300 lines of code. I'm not mad - I'm not just rewriting everything above to account for new index values.
processed = oneHotEncoded[, -c(1:5, 11, 13:14, 18, 20, 22, 25:26, 30:44, 49, 52:56, 61, 66, 70, 73:75, 83, 86, 92, 94, 99:104, 107:112, 114, 119:121, 127)]

#Encode mother's education
for (i in 1:1036){
  education = processed[[i, 19]]
  if (is.na(education)){
    processed$momFinishedPrimary[[i]] = NA
    processed$momFinishedSecondary[[i]] = NA
    processed$momFinishedTertiary[[i]] = NA
    next
  }
  processed$momFinishedPrimary[[i]] = 0
  processed$momFinishedSecondary[[i]] = 0
  processed$momFinishedTertiary[[i]] = 0
  if (education == 1){
    processed$momFinishedPrimary[[i]] = 1
  }else if (education == 2){
    processed$momFinishedSecondary[[i]] = 1
  }else if (education == 3){
    processed$momFinishedTertiary[[i]] = 1
  }
}

processed$momFinishedPrimary = as.numeric(as.character(processed$momFinishedPrimary))
processed$momFinishedSecondary = as.numeric(as.character(processed$momFinishedSecondary))
processed$momFinishedTertiary = as.numeric(as.character(processed$momFinishedTertiary))
processed = processed[, -19]

#Convert house floor materials into a binary for whether that floor is dust or not
for (i in 1:1036){
  if (is.na(sum(processed[i,61:65]))){
    processed$houseDustFloor[[i]] = NA
    next
  }
  if (sum(processed[i,61:65]) > 0){
    processed$houseDustFloor[[i]] = 0
  }else{
    processed$houseDustFloor[[i]] = 1
  }
}
processed$houseDustFloor = as.numeric(as.character(processed$houseDustFloor))
processed = processed[,-c(61:65)]

#Converting 1/2 binaries to 0/1
for (sample in 1:1036){
  for (factor in 53:56){
    if(is.na(processed[sample,factor])){
      next
    }
    if (processed[sample, factor] == 2){
      processed[sample, factor] = 0
    }
  }
}

#Every sample has the same answer for this variable - it tells us nothing
processed = processed[,-c(21)]
processed = processed[,-3]

#1HE washing hands after lat into "never", "with water", and "with soap" groups
for (i in 1:1036){
  if (is.na(processed[[i,38]])){
    processed$washHandsLatWater[[i]] = NA
    processed$washHandsLatWaterSoap[[i]] = NA
    next
  }
  else if (processed[[i,38]] == 2){
    processed$washHandsLatWater[[i]] = 0
    processed$washHandsLatWaterSoap[[i]] = 0
  }else{
    if (is.na(processed[[i,39]])){
      processed$washHandsLatWater[[i]] = NA
      processed$washHandsLatWaterSoap[[i]] = NA
      next
    }
    else if (processed[[i, 39]] == 0){
      processed$washHandsLatWater[[i]] = 1
      processed$washHandsLatWaterSoap[[i]] = 0
    }else if (processed[[i, 39]] == 1){
      processed$washHandsLatWater[[i]] = 0
      processed$washHandsLatWaterSoap[[i]] = 1
    }
  }
}
processed$washHandsLatWater = as.numeric(as.character(processed$washHandsLatWater))
processed$washHandsLatWaterSoap = as.numeric(as.character(processed$washHandsLatWaterSoap))
processed = processed[, -c(38:39)]

#1HE washing hands before eat into "never", "with water", "with soap" groups
for (i in 1:1036){
  if (is.na(processed[[i,38]])){
    processed$washHandsWaterB4Eat[[i]] = NA
    processed$washHandsSoapB4Eat[[i]] = NA
    next
  }
  else if (processed[[i,38]] == 2){
    processed$washHandsWaterB4Eat[[i]] = 0
    processed$washHandsSoapB4Eat[[i]] = 0
  }else{
    if (is.na(processed[[i,39]])){
      processed$washHandsWaterB4Eat[[i]] = NA
      processed$washHandsSoapB4Eat[[i]] = NA
      next
    }
    else if (processed[[i, 39]] == 0){
      processed$washHandsWaterB4Eat[[i]] = 1
      processed$washHandsSoapB4Eat[[i]] = 0
    }else if (processed[[i, 39]] == 1){
      processed$washHandsWaterB4Eat[[i]] = 0
      processed$washHandsSoapB4Eat[[i]] = 1
    }
  }
}
processed$washHandsWaterB4Eat = as.numeric(as.character(processed$washHandsWaterB4Eat))
processed$washHandsSoapB4Eat = as.numeric(as.character(processed$washHandsSoapB4Eat))
processed = processed[, -c(38:39)]

#Change ternary variables into binaries based on biological significance
for (sample in 1:1036){
  for (factor in c(33:37)){
    if (is.na(processed[[sample, factor]])){
      processed[[sample, factor]] = NA
      next
    }
    else if (processed[[sample, factor]] == 2){
      processed[[sample, factor]] = 0
    }else{
      processed[[sample, factor]] = 1
    }
  }
}
names(processed)[[33]] = "RiverBathing"
names(processed)[[34]] = "RiverLaundry"

for (sample in 1:1036){
  if (is.na(processed[[sample, 38]])){
    processed[[sample, 38]] = NA
    next
  }
 else if (processed[[sample, 38]] == 1){
   processed[[sample, 38]] = 0
 }else{
   processed[[sample, 38]] = 1
 }
}

for (sample in 1:1036){
  if (is.na(processed[[sample, 39]])){
    processed[[sample, 39]] = NA
    next
  }
  else if (processed[[sample, 39]] != 0){
    processed[[sample, 39]] = 0
  }else if (processed[[sample, 39]] == 0){
    processed[[sample, 39]] = 1
  }
}
names(processed)[[39]] = "NeverWashFruit"

#More ternary variables, but split differently according to biological significance
for (sample in 1:1036){
  for (factor in c(40:42)){
    if (is.na(processed[[sample, factor]])){
      processed[[sample, factor]] = NA
      next
    }
    else if (processed[[sample, factor]] != 0){
      processed[[sample, factor]] = 1
    }else{
      processed[[sample, factor]] = 0
    }
  }
}

#This loop below does two things: it re-formats data so 0 is false and 1 is true, OR turns already-correct but useless data into correctly-encoded data (i.e. "NoPhone" and "NoWaterInHouse")
for (sample in 1:1036){
  for (factor in c(11,13,23,31,32,36,37)){
    if (is.na(processed[[sample, factor]])){
      processed[[sample, factor]] = NA
      next
    }
    else if (processed[[sample, factor]] == 1){
      processed[[sample, factor]] = 0
    }else{
      processed[[sample, factor]] = 1
    }
  }
}
names(processed)[[11]] = "NailsNotTrimmed"
names(processed)[[13]] = "NoSchoolLatDoors"
names(processed)[[23]] = "NoPhone"
names(processed)[[28]] = "PotableWaterFromHouse"
names(processed)[[30]] = "DontTreatWater"
names(processed)[[31]] = "NoFamLat"
names(processed)[[32]] = "LatOutside"
names(processed)[[36]] = "DontUseSchoolLat"
names(processed)[[37]] = "DontUseTP"

for (i in 1:1036){
  if ((!is.na(processed[[i,8]]) & processed[[i,8]] == 1) |
      (!is.na(processed[[i,9]]) & processed[[i,9]] == 1) |
      (!is.na(processed[[i,10]]) & processed[[i,10]] == 1)){
    processed$SickLast2Weeks[i] = 1
  }else if (is.na(processed[[i,8]]) | is.na(processed[[i,9]]) | is.na(processed[[i,10]])){
    processed$SickLast2Weeks[i] = NA
  }else{
    processed$SickLast2Weeks[i] = 0
  }
}
processed = processed[,-c(8:10)]

for (i in 1:1036){
  if ((!is.na(processed[[i,8]]) & processed[[i,8]] == 1) |
      (!is.na(processed[[i,9]]) & processed[[i,9]] == 1)){
    processed$NailsMaintained[i] = 0
  }else if (is.na(processed[[i,8]]) | is.na(processed[[i,9]])){
    processed$NailsMaintained[i] = NA
  }else{
    processed$NailsMaintained[i] = 0
  }
}
processed = processed[,-c(8:10)]

for (i in 1:1036){
  if ((!is.na(processed[[i,8]]) & processed[[i,8]] == 1) |
      (!is.na(processed[[i,9]]) & processed[[i,9]] == 1)){
    processed$SchoolLatClean[i] = 0
  }else if (is.na(processed[[i,8]]) | is.na(processed[[i,9]])){
    processed$SchoolLatClean[i] = NA
  }else{
    processed$SchoolLatClean[i] = 0
  }
}
processed = processed[,-c(8:9, 11)]
processed = processed[,-c(10)]

for (i in 1:1036){
  if ((!is.na(processed[[i,11]]) & processed[[i,11]] == 1) |
      (!is.na(processed[[i,12]]) & processed[[i,12]] == 1)){
    processed$"Radio/TV"[i] = 1
  }else if (is.na(processed[[i,11]]) | is.na(processed[[i,12]])){
    processed$"Radio/TV"[i] = NA
  }else{
    processed$"Radio/TV"[i] = 0
  }
}
processed = processed[,-c(11:12)]
processed = processed[,-11]

processed = processed[,-c(16, 18)]

for (i in 1:1036){
  if ((!is.na(processed[[i,18]]) & processed[[i,18]] == 1) |
      (!is.na(processed[[i,19]]) & processed[[i,19]] == 1)){
    processed$RiverCleaning[i] = 1
  }else if (is.na(processed[[i,18]]) | is.na(processed[[i,19]])){
    processed$RiverCleaning[i] = NA
  }else{
    processed$RiverCleaning[i] = 0
  }
}
processed = processed[,-c(18,19)]

for (i in 1:1036){
  if ((!is.na(processed[[i,28]]) & processed[[i,28]] == 1) |
      (!is.na(processed[[i,29]]) & processed[[i,29]] == 1)){
    processed$OtherMeds[i] = 1
  }else if (is.na(processed[[i,28]]) | is.na(processed[[i,29]])){
    processed$OtherMeds[i] = NA
  }else{
    processed$OtherMeds[i] = 0
  }
}
processed = processed[,-c(28,29)]
processed = processed[,-28]
processed = processed[,-c(30:34)]

for (i in 1:1036){
  if ((!is.na(processed[[i,31]]) & processed[[i,31]] == 1) |
      (!is.na(processed[[i,32]]) & processed[[i,32]] == 1)){
    processed$"momFinished2Up"[i] = 1
  }else if (is.na(processed[[i,31]]) | is.na(processed[[i,32]])){
    processed$"momFinished2Up"[i] = NA
  }else{
    processed$"momFinished2Up"[i] = 0
  }
}
processed = processed[,-c(31, 32)]
names(processed)[[12]] = "SheepGoat"
names(processed)[[39]] = "RadioTV"
```


```{r Dependent Variable Calculations}
#Derive WAZ/HAZ/BAZ for specific analysis
#WAZ: Weight-relative-to-age Z-score (WHO says unreliable for ages 11+, so ignore older kids)
#HAZ: Height-relative-to-age Z-score 
#BAZ: BMI-relative-to-age Z-score

library(anthroplus)

depVars = anthroplus_zscores(sex = processed[["Sex"]]+1,
                             age_in_months = processed[["Age"]]*12,
                             weight_in_kg = processed[["weight"]],
                             height_in_cm = processed[["Height"]]*100
                             )

for (i in 1:1036){
  ZHeight = depVars$zhfa[[i]]
  processed$HAZ[[i]] = ZHeight
  processed$Stunting[[i]] = ifelse(ZHeight < -2, 1, 0 )
  
  ZBMI = depVars$zbfa[[i]]
  processed$BAZ[[i]] = ZBMI
  processed$Thinness[[i]] = ifelse (ZBMI < -2, 1, 0)
  
  if (processed[[i,"Age"]] < 11){ #scores not calculated for children 11 and up
    ZWeight = depVars$zwfa[[i]]
    processed$WAZ[[i]] = ZWeight
    processed$Wasting[[i]] = ifelse (ZWeight < -2, 1, 0)
  }else{
    processed$WAZ[[i]] = NA
    processed$Wasting[[i]] = NA
  }
}

processed$HAZ = as.numeric(as.character(processed$HAZ))
processed$Stunting = as.numeric(as.character(processed$Stunting))
processed$BAZ = as.numeric(as.character(processed$BAZ))
processed$Thinness = as.numeric(as.character(processed$Thinness))

#Some samples were too old/young for the WHO's package to calculate Stunting scores; we will remove them
for (i in 1:1036){
  if (is.na(processed$Stunting[i])){
    processed = processed[-i,]
  }
}
```



```{r Saving Preprocessing}
Stunting = processed[,-c(3, 4, 43, 45:48)]
imputed = kNN(Stunting, variable = colnames(Stunting), k = 5, impNA = TRUE) 
Stunting = subset(imputed, select = 1:41)

Thinness = processed[,-c(3, 4, 43:45, 47:48)]
imputed = kNN(Thinness, variable = colnames(Thinness), k = 5, impNA = TRUE) 
Thinness = subset(imputed, select = 1:41)

Wasting = processed[,-c(3, 4, 43:47)]
Wasting = subset(Wasting, Age < 11)
Wasting$Wasting = as.numeric(as.character(Wasting$Wasting))
imputed = kNN(Wasting, variable = colnames(Wasting), k = 5, impNA = TRUE) 
Wasting = subset(imputed, select = 1:41)

#write.csv(Stunting, "Stunting.csv")
#write.csv(Thinness, "Thinness.csv")
#write.csv(Wasting, "Wasting.csv")
```



```{r Data Structure Preparation, Subsetting}
# Stunting = read.csv("Stunting.csv")
# Thinness = read.csv("Thinness.csv")
# Wasting = read.csv("Wasting.csv")
################################################################################
DATA = list("Stunting" = list("Full" = list(),
                              "Urban" = list(),
                              "Nonurban" = list(),
                              "Male" = list(),
                              "Female" = list(),
                              "Youth" = list(),
                              "Adolescent" = list()
                              ),
            "Thinness" = list("Full" = list(),
                              "Urban" = list(),
                              "Nonurban" = list(),
                              "Male" = list(),
                              "Female" = list(),
                              "Youth" = list(),
                              "Adolescent" = list()
                              ),
            "Wasting" = list("Full" = list(),
                              "Urban" = list(),
                              "Nonurban" = list(),
                              "Male" = list(),
                              "Female" = list()
                              )
            )
DATA[["Stunting"]][["Full"]] = Stunting
DATA[["Stunting"]][["Urban"]] = subset(Stunting, Urban == 1)
DATA[["Stunting"]][["Nonurban"]] = subset(Stunting, Urban == 0)
DATA[["Stunting"]][["Male"]] = subset(Stunting, Sex == 0)
DATA[["Stunting"]][["Female"]] = subset(Stunting, Sex == 1)
DATA[["Stunting"]][["Youth"]] = subset(Stunting, Age < 11)
DATA[["Stunting"]][["Adolescent"]] = subset(Stunting, Age > 10)

DATA[["Thinness"]][["Full"]] = Thinness
DATA[["Thinness"]][["Urban"]] = subset(Thinness, Urban == 1)
DATA[["Thinness"]][["Nonurban"]] = subset(Thinness, Urban == 0)
DATA[["Thinness"]][["Male"]] = subset(Thinness, Sex == 0)
DATA[["Thinness"]][["Female"]] = subset(Thinness, Sex == 1)
DATA[["Thinness"]][["Youth"]] = subset(Thinness, Age < 11)
DATA[["Thinness"]][["Adolescent"]] = subset(Thinness, Age > 10)

DATA[["Wasting"]][["Full"]] = Wasting
DATA[["Wasting"]][["Urban"]] = subset(Wasting, Urban == 1)
DATA[["Wasting"]][["Nonurban"]] = subset(Wasting, Urban == 0)
DATA[["Wasting"]][["Male"]] = subset(Wasting, Sex == 0)
DATA[["Wasting"]][["Female"]] = subset(Wasting, Sex == 1)
#No Youth/Adolescent splits for Wasting; it's already limited to samples < 11 years old
```



```{r FS Splits}
library(caret)
library(tidyverse)
library(smotefamily)
library(VIM)
set.seed(13)

FSSets = list("Stunting" = list("Full" = list(),
                            "Urban" = list(),
                            "Nonurban" = list(),
                            "Male" = list(),
                            "Female" = list(),
                            "Youth" = list(),
                            "Adolescent" = list()
                            ),
            "Thinness" = list("Full" = list(),
                              "Urban" = list(),
                              "Nonurban" = list(),
                              "Male" = list(),
                              "Female" = list(),
                              "Youth" = list(),
                              "Adolescent" = list()
                              ),
            "Wasting" = list("Full" = list(),
                              "Urban" = list(),
                              "Nonurban" = list(),
                              "Male" = list(),
                              "Female" = list()
                              )
            )

for (i in 1:3){
  for (j in 1:7){
    if (i == 3 & (j == 6 | j == 7)){
      next
    }
    FSSets[[i]][[j]] = list("Unbalanced" = list(),
                        "Balanced" = list()
                        )
    set = DATA[[i]][[j]]
    response = names(DATA)[i]
    
    outerFolds = createFolds(set[,41], k = 10) #Create k splits
    Unbalanced = list(set[-outerFolds$Fold01, ], #Remove 10% of the data for each set
                          set[-outerFolds$Fold02, ], #to give us 10 different subsets
                          set[-outerFolds$Fold03, ],
                          set[-outerFolds$Fold04, ],
                          set[-outerFolds$Fold05, ],
                          set[-outerFolds$Fold06, ],
                          set[-outerFolds$Fold07, ],
                          set[-outerFolds$Fold08, ],
                          set[-outerFolds$Fold09, ],
                          set[-outerFolds$Fold10, ]
                          )
    for (k in 1:10){
      curSet = Unbalanced[[k]]
      innerFolds = createFolds(curSet[,41], k = 10)
      Unbalanced[[k]] = list(curSet[-innerFolds$Fold01, ], #Same as above but for
                            curSet[-innerFolds$Fold02, ], #sets we already have. 10*10 = 100
                            curSet[-innerFolds$Fold03, ],
                            curSet[-innerFolds$Fold04, ],
                            curSet[-innerFolds$Fold05, ],
                            curSet[-innerFolds$Fold06, ],
                            curSet[-innerFolds$Fold07, ],
                            curSet[-innerFolds$Fold08, ],
                            curSet[-innerFolds$Fold09, ],
                            curSet[-innerFolds$Fold10, ]
                            )
    }
    SMOTE = list()
    for (k in 1:10){ #Use SMOTE to create balanced versions of each of the training sets
      SMOTE[[k]] = list()
      for (l in 1:10){
        neighbors = sum(Unbalanced[[k]][[l]][,41]) - 1 #can't include itself
        if (neighbors > 5){
          neighbors = 5
        }
        SMOTE[[k]][[l]] = SMOTE(X = Unbalanced[[k]][[l]],
                              target = Unbalanced[[k]][[l]][,41],
                              K = neighbors,
                              dup_size = 1
                              )
        SMOTE[[k]][[l]]$data$class = NULL #Extra random variable, breaks modelling
        SMOTE[[k]][[l]] = SMOTE[[k]][[l]]$data
      }
    }
################################################################################
    # barplot(prop.table(table(Unbalanced[[1]][[1]][,41])),
    #     col = c("white", "darkgrey"),
    #     ylim = c(0, 1),
    #     xlim = c(0, 3),
    #     ylab = "Prevalence (%)",
    #     xlab = "Stunting",
    #     names = c("No", "Yes"),
    #     main = 'Unbalanced Set Class Distribution')
    # abline(h = 0)
    # 
    # barplot(prop.table(table(SMOTE[[1]][[1]]$data[,41])),
    #     col = c("white", "darkgrey"),
    #     ylim = c(0, 1),
    #     xlim = c(0, 3),
    #     ylab = "Prevalence (%)",
    #     xlab = "Stunting",
    #     names = c("No", "Yes"),
    #     main = 'Balanced  Set Class Distribution (SMOTE)')
    # abline(h = 0)
################################################################################
#Print ratios of class distributions so we know we have the right split. We want 3:1 here.
# table(Unbalanced[[1]][[1]]$response)[[1]][[1]]
# table(Unbalanced[[1]][[1]]$response)[[2]][[1]]
# table(Unbalanced[[1]][[1]]$response)[[1]][[1]]/table(Unbalanced[[1]][[1]]$response)[[2]][[1]]
# 
# table(SMOTE[[1]][[1]]$data$response)[[1]][[1]]
# table(SMOTE[[1]][[1]]$data$response)[[2]][[1]]
# table(SMOTE[[1]][[1]]$data$response)[[1]][[1]]/table(SMOTE[[1]][[1]]$data$response)[[2]][[1]]

  FSSets[[i]][[j]][["Unbalanced"]] = Unbalanced
  FSSets[[i]][[j]][["Balanced"]] = SMOTE
  }
}
```



```{r Feature Selection, warning = FALSE, output = FALSE}
set.seed(13)
#Preparing data structure to store results

NUM_FEATURES = 20 #Change this for different feature selection cutoffs
FSResults = list("Stunting" = list("Full" = list(),
                                   "Urban" = list(),
                                   "Nonurban" = list(),
                                   "Male" = list(),
                                   "Female" = list(),
                                   "Youth" = list(),
                                   "Adolescent" = list()
                                   ),
                 "Thinness" = list("Full" = list(),
                                   "Urban" = list(),
                                   "Nonurban" = list(),
                                   "Male" = list(),
                                   "Female" = list(),
                                   "Youth" = list(),
                                   "Adolescent" = list()
                                   ),
                 "Wasting" = list("Full" = list(),
                                  "Urban" = list(),
                                  "Nonurban" = list(),
                                  "Male" = list(),
                                  "Female" = list(),
                                  "Youth" = list(),
                                  "Adolescent" = list()
                                  )
                 )
for (i in 1:3){
  for (j in 1:7){
    FSResults[[i]][[j]] = list("Unbalanced" = list(),
                               "Balanced" = list()
                               )
    for (k in 1:2){
    FSResults[[i]][[j]][[k]] = list("ULR" = list(),
                                    "MLR" = list(),
                                    "ChiSq" = list(),
                                    "RelF" = list(),
                                    "mRMR" = list(),
                                    "JMI" = list()
                                    )
    }
  }
}
################################################################################
#Beginning loop iterations, filling out data structure
for (i in 1:3){
  for (j in 1:7){
    for (d in 1:2){
      if (i == 3 & (j == 6 | j == 7)){ #Wasting has no youth/adolescent subsets; skip them
        next
      }
      FeatureList = data.frame(Feature = character(),
                               ULR = double(),
                               MLR = double(),
                               ChiSq = double(),
                               IG = double(),
                               mRMR = double(),
                               JMi = double()
                               )
      for (k in 1:40){ #Make score markers for all features to track importance
        FeatureList[[k,1]] = names(Stunting)[k] #Name every row
        for (k1 in 2:7){
          FeatureList[[k,k1]] = 0 #Set initial scores for all 6 FS methods to 0
        }
      }
      #1 for unbalanced dataset; 2 for balanced dataset
      for (k in 1:10){
        for (l in 1:10){
          data = FSSets[[i]][[j]][[d]][[k]][[l]] #Load specific dataset we'll use in this run
################################################################################
#ULoR
library(broom)
library(car)
library(performance)
library(MASS)

          for (feature in 1:40){
            ULoR = glm(formula = paste0(names(data)[41],"~",names(data)[feature]),
                       data = data,
                       family = "binomial"
                       )
            regSummary = tidy(ULoR, exponentiate = TRUE, conf.level = 0.95)
            if (!is.na(regSummary[[2, 5]]) & regSummary[[2, 5]] < 0.05){
              FeatureList[[feature, 2]] = FeatureList[[feature, 2]] + 1
            }
          }
          FSResults[[i]][[j]][[d]][[1]] = FeatureList[,c(1,2)]
################################################################################
#MLoR
          MLoR = glm(formula = paste0(names(data)[41],"~."),
                     data = data,
                     family = "binomial"
          )
          regSummary = tidy(MLoR, exponentiate = TRUE, conf.level = 0.95)
          regSummary = regSummary[2:nrow(regSummary),] #Drop intercept
          regSummary = regSummary[order(regSummary$p.value), ]
          for (index in 1:NUM_FEATURES){
            Feature = regSummary[[index,1]]
            FeatureInd = which(names(Stunting) == Feature)
            FeatureList[[FeatureInd, 3]] = FeatureList[[FeatureInd, 3]] + 1
          }
          FSResults[[i]][[j]][[d]][[2]] = FeatureList[,c(1,3)]
################################################################################
#ChiSq
library(plyr)

          for (FeatureInd in 1:40){
            chisq = chisq.test(table(data[,FeatureInd],
                                     data[,41]
                                     )
                               )
            if (chisq$p.value < 0.05){
              FeatureList[[FeatureInd, 4]] = FeatureList[[FeatureInd, 4]] + 1
            }
          }
          FSResults[[i]][[j]][[d]][[3]] = FeatureList[,c(1,4)]
################################################################################
#mRMR. Pretty quick.
library(mRMRe)

          mrmr = mRMR.data(data = data)
          results = mRMR.classic("mRMRe.Filter",
                           data = mrmr,
                           target_indices = 41,
                           feature_count = NUM_FEATURES,
                           method = "exhaustive"
                           )
          for (index in 1:NUM_FEATURES){
            FeatureInd = results@filters[["41"]][[index,1]]
            FeatureList[[FeatureInd, 6]] = FeatureList[[FeatureInd, 6]] + 1
          }
          FSResults[[i]][[j]][[d]][[5]] = FeatureList[,c(1,6)]
################################################################################
#JMI
library(praznik)

          jmi = JMI(X = data[,-41],
                    Y = data[,41],
                    k = NUM_FEATURES
                    )
          for (index in 1:NUM_FEATURES){
            FeatureInd = jmi$selection[[index]]
            FeatureList[[FeatureInd, 7]] = FeatureList[[FeatureInd, 7]] + 1
          }
          FSResults[[i]][[j]][[d]][[6]] = FeatureList[,c(1,7)]
################################################################################
        }
      }
    }
  }
}
```



```{r FS Results}
T10Features = FSResults

for (i in 1:3){
  for (j in 1:7){
    if (i == 3 & (j == 6 | j == 7)){ #Wasting has no youth/adolescent subsets; skip them
      next
    }
    for (d in 1:2){
      for (k in 1:6){
        if (length(FSResults[[i]][[j]][[d]][[k]]) == 0){
          next
        }
        data = FSResults[[i]][[j]][[d]][[k]]
        Selected = integer()
        for (index in 1:40){
          if (data[[index, 2]] >= 90){
            Selected = c(Selected, index)
          }
        }
        T10Features[[i]][[j]][[d]][[k]] = T10Features[[i]][[j]][[d]][[k]][Selected,1]
      }
    }
  }
}
```



```{r Repeated Multivariate Logistic Regression (FS), warning = FALSE}
#Takes ~2 minutes.
results = data.frame(StuntingRejects = double(),
                     StuntingMaleRejects = double(),
                     StuntinFemaleRejects = double(),
                     StuntingUrbanRejects = double(),
                     StuntingNotUrbanRejects = double(),
                     StuntingYouthRejects = double(),
                     StuntingAdolescentRejects = double(),
                     
                     ThinnessRejects = double(),
                     ThinnessMaleRejects = double(),
                     StuntinFemaleRejects = double(),
                     ThinnessUrbanRejects = double(),
                     ThinnessNotUrbanRejects = double(),
                     ThinnessYouthRejects = double(),
                     ThinnessAdolescentRejects = double(),
                     
                     WastingRejects = double(),
                     WastingMaleRejects = double(),
                     StuntinFemaleRejects = double(), 
                     WastingUrbanRejects = double(), 
                     WastingNotUrbanRejects = double()
                     )
################################################################################
#Stunting PV-based feature selection & approximate odds ratios
for (factor in names(Stunting)[1:40]){
  results[[factor, 1]] = 0 #Must instantiate columns or next lines can't access them
}

for (i in 1:10){
  for (j in 1:10){
    index = 0
    UVLoR = glm(Stunting~.,
                data = UBStunting[[i]][[j]],
                family = "binomial"
                )
    regSummary = tidy(UVLoR, exponentiate = TRUE, conf.level = 0.95)
    for (factor in names(Stunting)[1:40]){
      index = index + 1
      if (!is.na(regSummary[[index, 5]]) && regSummary[[index, 5]] < 0.05){
        results[[factor, 1]] = results[[factor, 1]] + 1
      }
    }
  }
}
write.csv(results, "FS_R-UVLoR.csv")
```



```{r Multivariate Logistic Regression (OR), warning = FALSE}
#This MVLoR is for Odds Ratios, uses entire dataset.
#NOT used for feature selection for classifier models; do not mistake this data for the training/test set-derived repeated multivariate logistic regression above.
#library(devtools)
library(broom)
library(car)
library(performance)
library(MASS)
library(leaps)

OR_Stunting = glm(Stunting~., data = Stunting, family = "binomial")
write.csv(cbind(
          tidy(OR_Stunting, exponentiate = TRUE, conf.level = 0.95),
          p.adjust(summary(OR_Stunting)$coefficients[1:41,4],method = "BH"),
          exp(confint(OR_Stunting))),
          "MVLoR_Stunting.csv"
          )

StepStunting = stepAIC(OR_Stunting, direction = "both", trace = FALSE)   # Stepwise regression model
write.csv(cbind(
          tidy(StepStunting, exponentiate = TRUE, conf.level = 0.95),
          p.adjust(summary(StepStunting)$coefficients[,4],method = "BH"),
          exp(confint(StepStunting))),
          "MVLoR_SW_Stunting.csv"
          )

LIN_Stunting = lm(Stunting~., data = Stunting)
write.csv(cbind(
          tidy(LIN_Stunting, conf.level = 0.95),
          p.adjust(summary(LIN_Stunting)$coefficients[1:41,4],method = "BH"),
          confint(LIN_Stunting)),
          "MVLiR_Stunting.csv"
          )

StepLINStunting = stepAIC(LIN_Stunting, direction = "both", trace = FALSE)
write.csv(cbind(
          tidy(StepLINStunting, conf.level = 0.95),
          p.adjust(summary(StepLINStunting)$coefficients[,4],method = "BH"),
          confint(StepLINStunting)),
          "MVLiR_SW_Stunting.csv"
          )

summary(regsubsets(Stunting~., data = Stunting, nvmax = 5, method = "forward"))$adjr2
################################################################################
OR_Thinness = glm(Thinness~., data = Thinness, family = "binomial")
write.csv(cbind(
          tidy(OR_Thinness, exponentiate = TRUE, conf.level = 0.95),
          p.adjust(summary(OR_Thinness)$coefficients[1:41,4],method = "BH"),
          exp(confint(OR_Thinness))),
          "OR_Thinness.csv"
          )
StepThinness = stepAIC(OR_Thinness, direction = "both", trace = FALSE)   # Stepwise regression model
write.csv(cbind(
          tidy(StepThinness, exponentiate = TRUE, conf.level = 0.95),
          p.adjust(summary(StepThinness)$coefficients[,4],method = "BH"),
          exp(confint(StepThinness))),
          "MVLoR_SW_Thinness.csv"
          )

LIN_Thinness = lm(Thinness~., data = Thinness)
write.csv(cbind(
          tidy(LIN_Thinness, conf.level = 0.95),
          p.adjust(summary(LIN_Thinness)$coefficients[1:41,4],method = "BH"),
          confint(LIN_Thinness)),
          "MVLiR_Thinness.csv"
          )

StepLINThinness = stepAIC(LIN_Thinness, direction = "both", trace = FALSE)
write.csv(cbind(
          tidy(StepLINThinness, conf.level = 0.95),
          p.adjust(summary(StepLINThinness)$coefficients[,4],method = "BH"),
          confint(StepLINThinness)),
          "MVLiR_SW_Thinness.csv"
          )
################################################################################
OR_Wasting = glm(Wasting~., data = Wasting, family = "binomial")
write.csv(cbind(
          tidy(OR_Wasting, exponentiate = TRUE, conf.level = 0.95),
          p.adjust(summary(OR_Wasting)$coefficients[1:41,4],method = "BH"),
          exp(confint(OR_Wasting))),
          "OR_Wasting.csv"
          )
StepWasting = stepAIC(OR_Wasting, direction = "both", trace = FALSE)   # Stepwise regression model
write.csv(cbind(
          tidy(StepWasting, exponentiate = TRUE, conf.level = 0.95),
          p.adjust(summary(StepWasting)$coefficients[,4],method = "BH"),
          exp(confint(StepWasting))),
          "MVLoR_SW_Wasting.csv"
          )

LIN_Wasting = lm(Wasting~., data = Wasting)
write.csv(cbind(
          tidy(LIN_Wasting, conf.level = 0.95),
          p.adjust(summary(LIN_Wasting)$coefficients[1:41,4],method = "BH"),
          confint(LIN_Wasting)),
          "MVLiR_Wasting.csv"
          )

StepLINWasting = stepAIC(LIN_Wasting, direction = "both", trace = FALSE)
write.csv(cbind(
          tidy(StepLINWasting, conf.level = 0.95),
          p.adjust(summary(StepLINWasting)$coefficients[,4],method = "BH"),
          confint(StepLINWasting)),
          "MVLiR_SW_Wasting.csv"
          )

```



```{r Univariate Logistic Regression (OR)}
#Stunting PV-based feature selection & crude odds ratios

results = data.frame(Stunting_PV = double(),
                     Stunting_COR = double(),
                     "Stunting_2.5" = double(),
                     "Stunting_97.5" = double(),
                     
                     Thinness_PV = double(),
                     Thinness_COR = double(),
                     "Thinness_2.5" = double(),
                     "Thinness_97.5" = double(),
                     
                     Wasting_PV = double(),
                     Wasting_COR = double(),
                     "Wasting_2.5" = double(),
                     "Wasting_97.5" = double()
                     )
for (i in 1:40){
 results[i,] = 0
}
row.names(results) = names(Stunting)[1:40]
################################################################################
for (i in 1:40){
    UVLoR = glm(paste0("Stunting~",names(Stunting)[i]),
                data = Stunting,
                family = "binomial"
                )
    regSummary = tidy(UVLoR, exponentiate = TRUE, conf.level = 0.95)
    results[[1]][[i]] = regSummary[[2,"p.value"]]
    results[[2]][[i]] = regSummary[[2, "estimate"]]
    results[[3]][[i]] = confint(UVLoR)[[2,1]]
    results[[4]][[i]] = confint(UVLoR)[[2,2]]
    
}
################################################################################
for (i in 1:40){
    UVLoR = glm(paste0("Thinness~",names(Stunting)[i]),
                data = Thinness,
                family = "binomial"
                )
    regSummary = tidy(UVLoR, exponentiate = TRUE, conf.level = 0.95)
    results[[5]][[i]] = regSummary[[2,"p.value"]]
    results[[6]][[i]] = regSummary[[2, "estimate"]]
    results[[7]][[i]] = confint(UVLoR)[[2,1]]
    results[[8]][[i]] = confint(UVLoR)[[2,2]]
    
}
################################################################################
for (i in 1:40){
    UVLoR = glm(paste0("Wasting~",names(Stunting)[i]),
                data = Wasting,
                family = "binomial"
                )
    regSummary = tidy(UVLoR, exponentiate = TRUE, conf.level = 0.95)
    results[[9]][[i]] = regSummary[[2,"p.value"]]
    results[[10]][[i]] = regSummary[[2, "estimate"]]
    results[[11]][[i]] = confint(UVLoR)[[2,1]]
    results[[12]][[i]] = confint(UVLoR)[[2,2]]
    
}

################################################################################
write.csv(results, "UVLoR.csv")
```



```{r Association Rule Learning: Stunting}
#Pretty quick.
#I played around with support and confidence values until I got ~10 rules per iteration of the Apriori algorithm. 

#https://www.geeksforgeeks.org/apriori-algorithm-in-r-programming/
set.seed(13)

library(arules)
library(arulesViz)

ruleSet = data.frame(rules = character(),
                     support = numeric(),
                     confidence = numeric(),
                     coverage = numeric(),
                     lift = numeric(),
                     count = numeric())
################################################################################
#Male vs. Female associations on Stunting
ruleSet[nrow(ruleSet)+1, 1] = "Stunting:"
data = data.frame(lapply(Stunting, as.logical))


ruleSet[nrow(ruleSet)+1, 1] = "FEMALE:"
female = subset(data, Sex == TRUE)
female = female[,-2]
rules = apriori(female, 
                parameter = list(support = 0.01,
                                 confidence = 0.4,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Stunting")
                                  )
                )
#append(ruleSet, as(rules, "data.frame"))
#inspect(rules[1:10])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "MALE:"
male = subset(data, Sex == FALSE)
male = male[,-2]
rules = apriori(male, 
                parameter = list(support = 0.01,
                                 confidence = 0.62,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Stunting")
                                  )
                )
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
################################################################################
#Rural & suburban vs. urban rules on Stunting
ruleSet[nrow(ruleSet)+1, 1] = "NOTURBAN:"
rural = subset(data, Urban == FALSE)
rural = rural[,-c(6)]
rules = apriori(rural,
                parameter = list(support = 0.02,
                                 confidence = 0.46,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Stunting")
                                  )
                )
#inspect(rules)
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "URBAN:"
urban = subset(data, Urban == TRUE)
urban = urban[,-c(6)]
rules = apriori(urban, 
                parameter = list(support = 0.01,
                                 confidence = 0.42,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Stunting")
                                  )
                )
#inspect(rules[1:8])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
################################################################################
ruleSet[nrow(ruleSet)+1, 1] = "Stunting OVERALL:"
rules = apriori(data.frame(lapply(Stunting, as.logical)), 
                parameter = list(support = 0.01,
                                 confidence = 0.39,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Stunting")
                                  )
                )
#inspect(rules[1:10])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "StuntingYOUNG OVERALL:"

rules = apriori(data.frame(lapply(subset(Stunting, (Age < 11)), as.logical)), 
                parameter = list(support = 0.01,
                                 confidence = 0.54,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Stunting")
                                  )
                )
#inspect(rules[1:8])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "StuntingADOLESCENT OVERALL:"

rules = apriori(data.frame(lapply(subset(Stunting, (Age > 10)), as.logical)), 
                parameter = list(support = 0.01,
                                 confidence = 0.6,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Stunting")
                                  )
                )
#inspect(rules[1:8])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
```



```{r Association Rule Learning: Thinness}
set.seed(13)
################################################################################
ruleSet[nrow(ruleSet)+1, 1] = "Thinness:"
data = data.frame(lapply(Thinness, as.logical))


ruleSet[nrow(ruleSet)+1, 1] = "FEMALE:"
female = subset(data, Sex == TRUE)
female = female[,-2]
rules = apriori(female, 
                parameter = list(support = 0.002,
                                 confidence = 0.3,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Thinness")
                                  )
                )
#append(ruleSet, as(rules, "data.frame"))
#inspect(rules)
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "MALE:"
male = subset(data, Sex == FALSE)
male = male[,-2]
rules = apriori(male, 
                parameter = list(support = 0.002,
                                 confidence = 0.3,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Thinness")
                                  )
                )
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
################################################################################
#Rural & suburban vs. urban rules on Thinness
ruleSet[nrow(ruleSet)+1, 1] = "NOTURBAN:"
rural = subset(data, Urban == FALSE)
rural = rural[,-c(6)]
rules = apriori(rural,
                parameter = list(support = 0.005,
                                 confidence = 0.25,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Thinness")
                                  )
                )
#inspect(rules)
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "URBAN:"
urban = subset(data, Urban == TRUE)
urban = urban[,-c(6)]
rules = apriori(urban, 
                parameter = list(support = 0.002,
                                 confidence = 0.25,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Thinness")
                                  )
                )
#inspect(rules[1:8])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
################################################################################
ruleSet[nrow(ruleSet)+1, 1] = "Thinness OVERALL:"
rules = apriori(data.frame(lapply(Thinness, as.logical)), 
                parameter = list(support = 0.001,
                                 confidence = 0.2,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Thinness")
                                  )
                )
#inspect(rules[1:10])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "ThinnessYOUNG OVERALL:"

rules = apriori(data.frame(lapply(subset(Thinness, (Age < 11)), as.logical)), 
                parameter = list(support = 0.002,
                                 confidence = 0.25,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Thinness")
                                  )
                )
#inspect(rules[1:8])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "ThinnessADOLESCENT OVERALL:"

rules = apriori(data.frame(lapply(subset(Thinness, (Age > 10)), as.logical)), 
                parameter = list(support = 0.003,
                                 confidence = 0.2,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Thinness")
                                  )
                )
#inspect(rules[1:8])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
```




```{r Association Rule Learning: WastingYoung}
set.seed(13)
#Pretty quick.
#Again, same as above two blocks except only conducted on WastingYoung data.
################################################################################
ruleSet[nrow(ruleSet)+1, 1] = "Wasting:"
data = data.frame(lapply(Wasting, as.logical))


ruleSet[nrow(ruleSet)+1, 1] = "FEMALE:"
female = subset(data, Sex == TRUE)
female = female[,-2]
rules = apriori(female, 
                parameter = list(support = 0.01,
                                 confidence = 0.25,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Wasting")
                                  )
                )
#append(ruleSet, as(rules, "data.frame"))
#inspect(rules)
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "MALE:"
male = subset(data, Sex == FALSE)
male = male[,-2]
rules = apriori(male, 
                parameter = list(support = 0.01,
                                 confidence = 0.35,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Wasting")
                                  )
                )
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
################################################################################
#Rural & suburban vs. urban rules on Wasting
ruleSet[nrow(ruleSet)+1, 1] = "NOTURBAN:"
rural = subset(data, Urban == FALSE)
rural = rural[,-c(6)]
rules = apriori(rural,
                parameter = list(support = 0.01,
                                 confidence = 0.4,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Wasting")
                                  )
                )
#inspect(rules)
ruleSet = rbind(ruleSet, as(rules, "data.frame"))

ruleSet[nrow(ruleSet)+1, 1] = "URBAN:"
urban = subset(data, Urban == TRUE)
urban = urban[,-c(6)]
rules = apriori(urban, 
                parameter = list(support = 0.005,
                                 confidence = 0.23,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Wasting")
                                  )
                )
#inspect(rules[1:8])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
################################################################################
ruleSet[nrow(ruleSet)+1, 1] = "Wasting OVERALL:"
rules = apriori(data.frame(lapply(Wasting, as.logical)), 
                parameter = list(support = 0.005,
                                 confidence = 0.25,
                                 maxlen = 4,
                                 target = "rules"),
                appearance = list(default = "lhs", rhs = c("Wasting")
                                  )
                )
#inspect(rules[1:10])
ruleSet = rbind(ruleSet, as(rules, "data.frame"))
################################################################################
write.csv(ruleSet, "Association_Rules.csv", row.names = FALSE)
```


