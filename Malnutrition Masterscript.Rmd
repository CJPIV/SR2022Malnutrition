---
title: "Malnutrition Masterscript"
author: "Jim Perry"
date: "5/30/2022"
output: pdf_document
---
# TRAIN/TEST SPLITS: Prepares train/test splits for use in feature selection and
# classifier model training.
#####
```{r Train/Test Splits}
library(caret)
library(tidyverse)
library(smotefamily)

stunting = read.csv("C:/Users/Carmen Perry/Desktop/Colgate Stuff/Summer Research 2022/MalnutritionProject-20220523T125732Z-001/MalnutritionProject/Code/SR2022Malnutrition/Data/stunting.csv")
thinness = read.csv("C:/Users/Carmen Perry/Desktop/Colgate Stuff/Summer Research 2022/MalnutritionProject-20220523T125732Z-001/MalnutritionProject/Code/SR2022Malnutrition/Data/thinness.csv")

set.seed(13)
folds = createFolds(stunting$Stunting, k = 10) #Create k splits
testSets = list(stunting[folds$Fold01, ], stunting[folds$Fold02, ], stunting[folds$Fold03, ],
                stunting[folds$Fold04, ], stunting[folds$Fold05, ], stunting[folds$Fold06, ],
                stunting[folds$Fold07, ], stunting[folds$Fold08, ], stunting[folds$Fold09, ],
                stunting[folds$Fold10, ]
                )
trainSetsUB = list(stunting[-folds$Fold01, ], stunting[-folds$Fold02, ],
                   stunting[-folds$Fold03, ], stunting[-folds$Fold04, ],
                   stunting[-folds$Fold05, ], stunting[-folds$Fold06, ],
                   stunting[-folds$Fold07, ], stunting[-folds$Fold08, ],
                   stunting[-folds$Fold09, ], stunting[-folds$Fold10, ]
                   )
trainSetsSMOTE = list()
for (i in 1:10){ #Use SMOTE to create balanced versions of each of the training sets
  trainSetsSMOTE[[i]] = SMOTE(X = as.data.frame(trainSetsUB[[1]]),
                              target = trainSetsUB[[1]]$Stunting,
                              K = 5,
                              dup_size = 3
                              )
}

barplot(prop.table(table(trainSetsUB[[1]]$Stunting)),
        col = c("white", "darkgrey"),
        ylim = c(0, 1),
        xlim = c(0, 3),
        ylab = "Prevalence (%)",
        xlab = "Stunting",
        names = c("No", "Yes"),
        main = 'Stunting Training Set Class Distribution (Unbalanced)')
abline(h = 0)

barplot(prop.table(table(trainSetsSMOTE[[1]]$data$Stunting)),
        col = c("white", "darkgrey"),
        ylim = c(0, 1),
        xlim = c(0, 3),
        ylab = "Prevalence (%)",
        xlab = "Stunting",
        names = c("No", "Yes"),
        main = 'Stunting Training Set Class Distribution (SMOTE)')
abline(h = 0)
# Following code writes each training set to its own .csv files for use in other scripts.
#####
# FS_UB_Stunting = rbind(testSets[1:10])
# FS_SMOTE_Stunting = rbind(trainSetsSMOTE[1:10])
# write.csv(FS_UB_Stunting, "FS_UB_Stunting.csv")
# write.csv(FS_SMOTE_Stunting, "FS_SMOTE_Stunting.csv")
```

#####
# FEATURE SELECTION: Selects important model features to reduce noise and help prevent 
# overfitting.
#####
```{r ReliefF}
#This one takes a while.
library(FSelectorRcpp)

FS_RLF_UB_Stunting = list()
for (i in 1:10){
  relF = relief(Stunting~.,
                as.data.frame(trainSetsUB[[i]]),
                neighboursCount = 5
                )
  FS_RLF_UB_Stunting[[i]] = relF[order(relF$importance), ] #returns a list of important features and their ranking
}
```

```{r InfoGain}
#This one is pretty quick.
library(FSelectorRcpp)

FS_IG_UB_Stunting = list()
for (i in 1:10){
  infogain = information_gain(formula = Stunting~.,
                              data = as.data.frame(trainSetsUB[[i]]),
                              type = 'infogain',
                              equal = TRUE
                              )
  FS_IG_UB_Stunting[[i]] = infogain[order(infogain$importance), ]
}

FS_IG_SMOTE_Stunting = list()
for (i in 1:10){
  infogain = information_gain(formula = Stunting~.,
                              data = as.data.frame(trainSetsSMOTE[[i]]$data),
                              type = 'infogain',
                              equal = TRUE
                              )
  FS_IG_SMOTE_Stunting[[i]] = infogain[order(infogain$importance), ] #returns a list of important features and their ranking
}

```

```{r mRMR}
library(mRMRe)

mrmr = mRMR.data(data = stunting)
FS_MRMR_Stunting = mRMR.classic(data = mrmr)
```

```{r JMI}
#This one takes a while.
library(JMI)

FS_JMI_UB_Stunting = list()
FS_JMI_SMOTE_Stunting = list()

for (i in 1:10){
  FS_JMI_UB_Stunting[[i]] = JMI(x = trainSetsUB[[i]], 
                                y = trainSetsUB[[i]]$Stunting
                                )
}
```

```{r Literature-Based}
FS_LB_UB_Stunting = list()
FS_LB_SMOTE_Stunting = list()
FS_LB_UB_Thinness = list()
FS_LB_SMOTE_Thinness = list()
```

#####
# CLASSIFIER MODELS:
#####
```{r Classifier Models}

```

#####
# ASSOCIATION RULE LEARNING:
#####
```{r Association Rule Learning}

```